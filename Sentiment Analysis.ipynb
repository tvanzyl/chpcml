{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural language Prorcessing (NLP)\n",
    "\n",
    "\n",
    "## Movie Reviews\n",
    "\n",
    "Following this tutorial on scikit-learn.org: https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "\n",
    "Adapted to work with off-line movie review corpus.\n",
    "Also, check out documentation on dataset loading: http://scikit-learn.org/stable/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading all movie files.\n",
    "movie = load_files('./movie_reviews/', shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target names (\"classes\") are automatically generated from subfolder names.\n",
    "movie.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"arnold schwarzenegger has been an icon for action enthusiasts , since the late 80's , but lately his films have been very sloppy and the one-liners are getting worse . \\nit's hard seeing arnold as mr . freeze in batman and robin , especially when he says tons of ice jokes , but hey he got 15 million , what's it matter to him ? \\nonce again arnold has signed to do another expensive blockbuster , that can't compare with the likes of the terminator series , true lies and even eraser . \\nin this so cal\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First file seems to be about a Schwarzenegger movie. \n",
    "movie.data[0][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./movie_reviews/neg/cv405_21868.txt'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First file is in \"neg\" folder\n",
    "movie.filenames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First file is a negative review and is mapped to 0 index 'neg' in target_names\n",
    "movie.target[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing out CountVectorizer & TF-IDF\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three tiny \"documents\"\n",
    "docs = ['a HPC is a HPC is a HPC is a HPC.',\n",
    "        'Oh, what a fine practical this is.',\n",
    "        \"A practical ain't over till it's truly over.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a CountVectorizer to its \n",
    "#    default one (which ignores punctuation and stopwords). \n",
    "# Minimum document frequency set to 1. \n",
    "fooVzer = CountVectorizer(min_df=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hpc': 2,\n",
       " 'is': 3,\n",
       " 'oh': 5,\n",
       " 'what': 11,\n",
       " 'fine': 1,\n",
       " 'practical': 7,\n",
       " 'this': 8,\n",
       " 'ain': 0,\n",
       " 'over': 6,\n",
       " 'till': 9,\n",
       " 'it': 4,\n",
       " 'truly': 10}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1) fit: adapts fooVzer to the supplied text data (rounds up top words into vector space) \n",
    "# (2) transform: creates and returns a count-vectorized output of docs\n",
    "docs_counts = fooVzer.fit_transform(docs)\n",
    "\n",
    "# fooVzer now contains vocab dictionary which maps unique words to indexes\n",
    "fooVzer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 12)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# docs_counts has a dimension of 3 (document count) by 12 (# of unique words)\n",
    "docs_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 1, 0, 2, 1, 0, 1, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this vector is small enough to view in a full, non-sparse form! \n",
    "docs_counts.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets Pretty print that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hpc</th>\n",
       "      <th>is</th>\n",
       "      <th>oh</th>\n",
       "      <th>what</th>\n",
       "      <th>fine</th>\n",
       "      <th>practical</th>\n",
       "      <th>this</th>\n",
       "      <th>ain</th>\n",
       "      <th>over</th>\n",
       "      <th>till</th>\n",
       "      <th>it</th>\n",
       "      <th>truly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hpc  is  oh  what  fine  practical  this  ain  over  till  it  truly\n",
       "0    4   3   0     0     0          0     0    0     0     0   0      0\n",
       "1    0   1   1     1     1          1     1    0     0     0   0      0\n",
       "2    0   0   0     0     0          1     0    1     2     1   1      1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({i:docs_counts.toarray()[:,j] for i,j in fooVzer.vocabulary_.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert raw frequency counts into TF-IDF (Term Frequency -- Inverse Document Frequency)\n",
    "\n",
    "https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n",
    "\n",
    "\n",
    "Term Frequency\n",
    "$$ \\mathrm {tf} (t,d)=0.5+0.5\\cdot {\\frac {f_{t,d}}{\\max\\{f_{t',d}:t'\\in d\\}}}$$\n",
    "\n",
    "We denote the raw count by $f_{t,d}$\n",
    "\n",
    "Inverse Document Frequency\n",
    "$$\\mathrm{idf}(t, D) =  \\log \\frac{N}{|\\{d \\in D: t \\in d\\}|}$$\n",
    "\n",
    "For document $d$ in corpus $D$\n",
    "\n",
    "TF-IDF\n",
    "$$\\mathrm {tfidf} (t,d,D)=\\mathrm {tf} (t,d)\\cdot \\mathrm {idf} (t,D)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert raw frequency counts into TF-IDF (Term Frequency -- Inverse Document Frequency) values\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "fooTfmer = TfidfTransformer()\n",
    "\n",
    "# Again, fit and transform\n",
    "docs_tfidf = fooTfmer.fit_transform(docs_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.86862987, 0.49546155, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.44036207, 0.        , 0.3349067 , 0.        ,\n",
       "        0.44036207, 0.        , 0.3349067 , 0.44036207, 0.        ,\n",
       "        0.        , 0.44036207],\n",
       "       [0.34142622, 0.        , 0.        , 0.        , 0.34142622,\n",
       "        0.        , 0.68285244, 0.25966344, 0.        , 0.34142622,\n",
       "        0.34142622, 0.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF values\n",
    "docs_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And in pretty print\n",
    "\n",
    "* raw counts have been normalized against document length, \n",
    "* terms that are found across many docs are weighted down ('a' vs. 'hpc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hpc</th>\n",
       "      <th>is</th>\n",
       "      <th>oh</th>\n",
       "      <th>what</th>\n",
       "      <th>fine</th>\n",
       "      <th>practical</th>\n",
       "      <th>this</th>\n",
       "      <th>ain</th>\n",
       "      <th>over</th>\n",
       "      <th>till</th>\n",
       "      <th>it</th>\n",
       "      <th>truly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.86863</td>\n",
       "      <td>0.495462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.334907</td>\n",
       "      <td>0.440362</td>\n",
       "      <td>0.440362</td>\n",
       "      <td>0.440362</td>\n",
       "      <td>0.334907</td>\n",
       "      <td>0.440362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.259663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341426</td>\n",
       "      <td>0.682852</td>\n",
       "      <td>0.341426</td>\n",
       "      <td>0.341426</td>\n",
       "      <td>0.341426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       hpc        is        oh      what      fine  practical      this  \\\n",
       "0  0.86863  0.495462  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "1  0.00000  0.334907  0.440362  0.440362  0.440362   0.334907  0.440362   \n",
       "2  0.00000  0.000000  0.000000  0.000000  0.000000   0.259663  0.000000   \n",
       "\n",
       "        ain      over      till        it     truly  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.341426  0.682852  0.341426  0.341426  0.341426  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({i:docs_tfidf.toarray()[:,j] for i,j in fooVzer.vocabulary_.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A list of new documents\n",
    "newdocs = [\"I have a hpc and a pc.\", \n",
    "           \"What a beautiful practical.\"]\n",
    "\n",
    "# This time, no fitting needed: transform the new docs into count-vectorized form\n",
    "# Unseen words ('pc', 'beautiful', 'have', etc.) are ignored\n",
    "newdocs_counts = fooVzer.transform(newdocs)\n",
    "newdocs_counts.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hpc</th>\n",
       "      <th>is</th>\n",
       "      <th>oh</th>\n",
       "      <th>what</th>\n",
       "      <th>fine</th>\n",
       "      <th>practical</th>\n",
       "      <th>this</th>\n",
       "      <th>ain</th>\n",
       "      <th>over</th>\n",
       "      <th>till</th>\n",
       "      <th>it</th>\n",
       "      <th>truly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hpc  is  oh  what  fine  practical  this  ain  over  till  it  truly\n",
       "0    1   0   0     0     0          0     0    0     0     0   0      0\n",
       "1    0   0   0     1     0          1     0    0     0     0   0      0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({i:newdocs_counts.toarray()[:,j] for i,j in fooVzer.vocabulary_.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.60534851, 0.        , 0.        ,\n",
       "        0.        , 0.79596054]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again, transform using tfidf \n",
    "newdocs_tfidf = fooTfmer.transform(newdocs_counts)\n",
    "newdocs_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hpc</th>\n",
       "      <th>is</th>\n",
       "      <th>oh</th>\n",
       "      <th>what</th>\n",
       "      <th>fine</th>\n",
       "      <th>practical</th>\n",
       "      <th>this</th>\n",
       "      <th>ain</th>\n",
       "      <th>over</th>\n",
       "      <th>till</th>\n",
       "      <th>it</th>\n",
       "      <th>truly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.795961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.605349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hpc   is   oh      what  fine  practical  this  ain  over  till   it  truly\n",
       "0  1.0  0.0  0.0  0.000000   0.0   0.000000   0.0  0.0   0.0   0.0  0.0    0.0\n",
       "1  0.0  0.0  0.0  0.795961   0.0   0.605349   0.0  0.0   0.0   0.0  0.0    0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({i:newdocs_tfidf.toarray()[:,j] for i,j in fooVzer.vocabulary_.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to real data: movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(movie.data, \n",
    "                                                          movie.target, \n",
    "                                                          test_size = 0.20, \n",
    "                                                          random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize CountVectorizer\n",
    "movieVzer= CountVectorizer(min_df=2, max_features=3000) # use top 3000 words only. 80.03% acc.\n",
    "# movieVzer = CountVectorizer(min_df=2)                 # use all 21K words. Higher accuracy???\n",
    "\n",
    "# fit and tranform using training text \n",
    "docs_train_counts = movieVzer.fit_transform(docs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2279"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'screen' is found in the corpus, mapped to index 2290\n",
    "movieVzer.vocabulary_.get('screen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2286"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Likewise, Mr. Steven Seagal is present...\n",
    "movieVzer.vocabulary_.get('seagal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 3000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# huge dimensions! 1,600 documents, 3K unique terms. \n",
    "docs_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert raw frequency counts into TF-IDF values\n",
    "movieTfmer = TfidfTransformer()\n",
    "docs_train_tfidf = movieTfmer.fit_transform(docs_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 3000)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same dimensions, now with tf-idf values instead of raw frequency counts\n",
    "docs_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The feature extraction functions and training data are ready.\n",
    "* Vectorizer and transformer have been built from the training data\n",
    "* Training data text was also turned into TF-IDF vector form\n",
    "\n",
    "## Next up: test data\n",
    "* You have to prepare the test data using the same feature extraction scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the fitted vectorizer and transformer, tranform the test data\n",
    "docs_test_counts = movieVzer.transform(docs_test)\n",
    "docs_test_tfidf = movieTfmer.transform(docs_test_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing a SGDClassifier classifier\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now ready to build a classifier. \n",
    "# We will use Multinominal Naive Bayes as our model\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tvzyl/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Logistic Regression Classifier. Again, we call it \"fitting\"\n",
    "clf = SGDClassifier(random_state=42)\n",
    "clf.fit(docs_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.835"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the Test set results, find accuracy\n",
    "y_pred = clf.predict(docs_test_tfidf)\n",
    "sklearn.metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consfusion Matrix\n",
    "\n",
    "https://en.wikipedia.org/wiki/Confusion_matrix\n",
    "\n",
    "<table class=\"wikitable\" style=\"border:none; margin-top:0;\">\n",
    "<tbody><tr>\n",
    "<th style=\"background:white; border:none;\" colspan=\"2\" rowspan=\"2\">\n",
    "</th>\n",
    "<th colspan=\"3\" style=\"background:none;\">Actual class\n",
    "</th></tr>\n",
    "<tr>\n",
    "<th>Cat\n",
    "</th>\n",
    "<th>Non-cat\n",
    "</th></tr>\n",
    "<tr>\n",
    "<th rowspan=\"3\" style=\"height:6em;\"><div style=\"display: inline-block; -ms-transform: rotate(-90deg); -webkit-transform: rotate(-90deg); transform: rotate(-90deg);;\">Predicted<br> class</div>\n",
    "</th>\n",
    "<th>Cat\n",
    "</th>\n",
    "<td>5 True Positives\n",
    "</td>\n",
    "<td>2 False Positives\n",
    "</td></tr>\n",
    "<tr>\n",
    "<th>Non-cat\n",
    "</th>\n",
    "<td>3 False Negatives\n",
    "</td>\n",
    "<td>3 True Negatives\n",
    "</td></tr>\n",
    "</tbody></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Pos</th>\n",
       "      <th>Actual Neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predict Pos</th>\n",
       "      <td>167</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predict Neg</th>\n",
       "      <td>27</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Actual Pos  Actual Neg\n",
       "Predict Pos         167          39\n",
       "Predict Neg          27         167"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "pd.DataFrame(cm, index=['Predict Pos', 'Predict Neg'], columns=['Actual Pos', 'Actual Neg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: We  should use cross-validation to find the hyper-parameters to our models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying the classifier on fake movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# very short and fake movie reviews\n",
    "reviews_new = ['This movie was excellent', 'Absolute joy ride', \n",
    "               'Arnold was terrible', 'Arnold was excellent.', \n",
    "               'This was certainly a movie', 'Two thumbs up', 'I fell asleep halfway through', \n",
    "               \"We can't wait for the sequel!!\", 'I cannot recommend this highly enough', \n",
    "               'His performance was Oscar-worthy.', 'Steven Seagal was amazing',\n",
    "               'instant classic.', 'Steven Seagal was amazing. His performance was Oscar-worthy.']\n",
    "\n",
    "reviews_new_counts = movieVzer.transform(reviews_new)         # turn text into count vector\n",
    "reviews_new_tfidf = movieTfmer.transform(reviews_new_counts)  # turn into tfidf vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have classifier make a prediction\n",
    "pred = clf.predict(reviews_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'This movie was excellent' => pos\n",
      "'Absolute joy ride' => pos\n",
      "'Arnold was terrible' => neg\n",
      "'Arnold was excellent.' => pos\n",
      "'This was certainly a movie' => neg\n",
      "'Two thumbs up' => neg\n",
      "'I fell asleep halfway through' => neg\n",
      "\"We can't wait for the sequel!!\" => neg\n",
      "'I cannot recommend this highly enough' => neg\n",
      "'His performance was Oscar-worthy.' => pos\n",
      "'Steven Seagal was amazing' => neg\n",
      "'instant classic.' => neg\n",
      "'Steven Seagal was amazing. His performance was Oscar-worthy.' => neg\n"
     ]
    }
   ],
   "source": [
    "# print out results\n",
    "for review, category in zip(reviews_new, pred):\n",
    "    print('%r => %s' % (review, movie.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now your turn\n",
    "\n",
    "Below we have a dataset of airline tweets.\n",
    "\n",
    "1. Build a classifier to detect the sentiment of a tweet.\n",
    "2. Find your accuracy and confusion matrix on a test set.\n",
    "\n",
    "**Advanced:**\n",
    "\n",
    "3. Use Cross-Validation to determine some of your hyper-parameters.\n",
    "4. Compare a few different classifiers to see which performs best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import Bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_tweets = pd.read_csv('./us_airlines/Tweets.csv')\n",
    "airline_tweets = airline_tweets[airline_tweets.airline_sentiment_confidence > 0.5]\n",
    "airline = Bunch(\n",
    "    data = [i for i in airline_tweets.text],\n",
    "    target_names = ['neg', 'neu', 'pos'],\n",
    "    target_values = [-1,0,1],\n",
    "    target = np.asarray([{'positive':1,'neutral':0,'negative':-1}[i] for i in airline_tweets.airline_sentiment])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  0, -1, ...,  0, -1,  0]), 14404)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline.target, len(airline.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['neg', 'neu', 'pos'], [-1, 0, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline.target_names, airline.target_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"@VirginAmerica I didn't today... Must mean I need to take another trip!\", 0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline.data[1], airline.target[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
